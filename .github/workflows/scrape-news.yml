name: Scrape News

on:
  schedule:
    - cron: "0 */12 * * *"  # This schedules the job to run every 12 hours.
  workflow_dispatch:  # This allows you to trigger the workflow manually if needed.

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v2  # This checks out your code from the repository.

    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.x'  # Use the latest Python version.

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt  # Install your dependencies (flask, requests, beautifulsoup4)

    - name: Run scraper
      run: |
        python app.py  # Run your scraper script.
        
    - name: Commit news.json
      run: |
        git config --global user.name "GitHub Actions"
        git config --global user.email "your-email@example.com"
        git add news.json
        git commit -m "Update news.json with new content"
        git push
